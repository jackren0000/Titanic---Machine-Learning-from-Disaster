{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e587eb8",
   "metadata": {
    "papermill": {
     "duration": 0.009309,
     "end_time": "2024-02-08T13:21:37.726269",
     "exception": false,
     "start_time": "2024-02-08T13:21:37.716960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Data Analysis of Titanic Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2f737",
   "metadata": {
    "papermill": {
     "duration": 0.008501,
     "end_time": "2024-02-08T13:21:37.743755",
     "exception": false,
     "start_time": "2024-02-08T13:21:37.735254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define the objective:\n",
    "*The goal of this data analysis is to find relevance and patterns of the dataset, using statistical method and data visualization to show a clear relationship between different features within the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ba3d1b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:37.762850Z",
     "iopub.status.busy": "2024-02-08T13:21:37.762493Z",
     "iopub.status.idle": "2024-02-08T13:21:43.618647Z",
     "shell.execute_reply": "2024-02-08T13:21:43.617846Z"
    },
    "papermill": {
     "duration": 5.868262,
     "end_time": "2024-02-08T13:21:43.620992",
     "exception": false,
     "start_time": "2024-02-08T13:21:37.752730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import KNN from scikit-learn library (especially for ML)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import data split method \n",
    "from sklearn.model_selection import train_test_split\n",
    "# import K-fold cross-validation method\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# import evaluation method\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# normalize the data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# import PyTorch for Deep Learning\n",
    "import torch\n",
    "# import neural network\n",
    "from torch import nn\n",
    "# import relative math functions\n",
    "import torch.nn.functional as F\n",
    "# import PyTorch DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7eeff",
   "metadata": {
    "papermill": {
     "duration": 0.008514,
     "end_time": "2024-02-08T13:21:43.638579",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.630065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Collection:\n",
    "*Collect the relevant data from competition website, then convert it into pandas DataFrame.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c83e78a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:43.657627Z",
     "iopub.status.busy": "2024-02-08T13:21:43.656935Z",
     "iopub.status.idle": "2024-02-08T13:21:43.685515Z",
     "shell.execute_reply": "2024-02-08T13:21:43.684791Z"
    },
    "papermill": {
     "duration": 0.04048,
     "end_time": "2024-02-08T13:21:43.687713",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.647233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### load the data\n",
    "DIR_PATH = '/kaggle/input/titanic'\n",
    "train = pd.read_csv(os.path.join(DIR_PATH, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DIR_PATH, 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53135cd8",
   "metadata": {
    "papermill": {
     "duration": 0.008778,
     "end_time": "2024-02-08T13:21:43.705847",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.697069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Clearning:\n",
    "*Clean the unhelpful columns, NaN value, duplicates and inconsistencies.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bc2839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:43.725521Z",
     "iopub.status.busy": "2024-02-08T13:21:43.725141Z",
     "iopub.status.idle": "2024-02-08T13:21:43.752315Z",
     "shell.execute_reply": "2024-02-08T13:21:43.751146Z"
    },
    "papermill": {
     "duration": 0.039712,
     "end_time": "2024-02-08T13:21:43.754310",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.714598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba91562",
   "metadata": {
    "papermill": {
     "duration": 0.009035,
     "end_time": "2024-02-08T13:21:43.772208",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.763173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note: 'Age', 'Cabin' and 'Embarked' columns have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e79b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:43.791061Z",
     "iopub.status.busy": "2024-02-08T13:21:43.790716Z",
     "iopub.status.idle": "2024-02-08T13:21:43.810759Z",
     "shell.execute_reply": "2024-02-08T13:21:43.809838Z"
    },
    "papermill": {
     "duration": 0.031732,
     "end_time": "2024-02-08T13:21:43.812676",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.780944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0826ed35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:43.832302Z",
     "iopub.status.busy": "2024-02-08T13:21:43.832042Z",
     "iopub.status.idle": "2024-02-08T13:21:43.838215Z",
     "shell.execute_reply": "2024-02-08T13:21:43.837410Z"
    },
    "papermill": {
     "duration": 0.018226,
     "end_time": "2024-02-08T13:21:43.840124",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.821898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    # drop unhelpful feature from the observation\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "    # impute missing ages with the median\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "    # impute missing ages with the mean\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n",
    "    # impute missing 'Embarked' values with the mode\n",
    "    most_common_embarked = df['Embarked'].mode()[0]\n",
    "    df['Embarked'] = df['Embarked'].fillna(most_common_embarked)\n",
    "\n",
    "    # convert categorical data into numerical data\n",
    "    # use get_dummies() to perform one-hot encoding on 'Sex' and 'Embarked'\n",
    "    df = pd.get_dummies(df, columns=['Sex', 'Embarked'], dtype=int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b93b50f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:43.859444Z",
     "iopub.status.busy": "2024-02-08T13:21:43.859172Z",
     "iopub.status.idle": "2024-02-08T13:21:43.874604Z",
     "shell.execute_reply": "2024-02-08T13:21:43.873751Z"
    },
    "papermill": {
     "duration": 0.027367,
     "end_time": "2024-02-08T13:21:43.876600",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.849233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = data_cleaning(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bea7d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:43.896208Z",
     "iopub.status.busy": "2024-02-08T13:21:43.895957Z",
     "iopub.status.idle": "2024-02-08T13:21:43.908952Z",
     "shell.execute_reply": "2024-02-08T13:21:43.908047Z"
    },
    "papermill": {
     "duration": 0.025342,
     "end_time": "2024-02-08T13:21:43.911118",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.885776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "0         0       3  22.0      1      0   7.2500           0         1   \n",
       "1         1       1  38.0      1      0  71.2833           1         0   \n",
       "2         1       3  26.0      0      0   7.9250           1         0   \n",
       "3         1       1  35.0      1      0  53.1000           1         0   \n",
       "4         0       3  35.0      0      0   8.0500           0         1   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           0           1  \n",
       "1           1           0           0  \n",
       "2           0           0           1  \n",
       "3           0           0           1  \n",
       "4           0           0           1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# revisit the cleaned dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c20106",
   "metadata": {
    "papermill": {
     "duration": 0.009526,
     "end_time": "2024-02-08T13:21:43.931131",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.921605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da159c8b",
   "metadata": {
    "papermill": {
     "duration": 0.009495,
     "end_time": "2024-02-08T13:21:43.950113",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.940618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Feature Engineering:\n",
    "*Create new features from existing ones to improve model performance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c165f2",
   "metadata": {
    "papermill": {
     "duration": 0.009474,
     "end_time": "2024-02-08T13:21:43.969287",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.959813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f1a7f21",
   "metadata": {
    "papermill": {
     "duration": 0.009935,
     "end_time": "2024-02-08T13:21:43.988856",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.978921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Transformation:\n",
    "*Normalize, scale, or encode data as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f9646e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:44.010420Z",
     "iopub.status.busy": "2024-02-08T13:21:44.009571Z",
     "iopub.status.idle": "2024-02-08T13:21:44.130284Z",
     "shell.execute_reply": "2024-02-08T13:21:44.129300Z"
    },
    "papermill": {
     "duration": 0.133954,
     "end_time": "2024-02-08T13:21:44.132298",
     "exception": false,
     "start_time": "2024-02-08T13:21:43.998344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separate the feature matrix and the target value\n",
    "X = train.drop('Survived', axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "# normalize the data\n",
    "# split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on training set only\n",
    "scaler.fit(X_train)\n",
    "# apply transform to both the training set and the test set\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a4217",
   "metadata": {
    "papermill": {
     "duration": 0.009204,
     "end_time": "2024-02-08T13:21:44.151563",
     "exception": false,
     "start_time": "2024-02-08T13:21:44.142359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1f9d17",
   "metadata": {
    "papermill": {
     "duration": 0.009007,
     "end_time": "2024-02-08T13:21:44.169898",
     "exception": false,
     "start_time": "2024-02-08T13:21:44.160891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> > ### K-Nearest Neighbors: \n",
    "> > This is a type of instance-based supervised learning algorithm used for both classification and regression.  \n",
    "> \n",
    "> Pros:\n",
    "> 1. simple to understand and implement.\n",
    "> 2. no need to build a model, tune several parameters.\n",
    "> 3. the algorithm is versatile, it can be used for classification, regression and search (as in recommender system).\n",
    "> \n",
    "> Cons:\n",
    "> 1. the algorithm gets significantly slower as the dataset grows.\n",
    "> 2. requires high memory - needs to store all the training data.\n",
    "> 3. sensitive to the scale of the data and irrelevant features.\n",
    "> 4. typically not as accurate as more sophisticated methods, especially on datasets with a lot of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03bf392a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:44.189738Z",
     "iopub.status.busy": "2024-02-08T13:21:44.189417Z",
     "iopub.status.idle": "2024-02-08T13:21:44.195792Z",
     "shell.execute_reply": "2024-02-08T13:21:44.194957Z"
    },
    "papermill": {
     "duration": 0.018643,
     "end_time": "2024-02-08T13:21:44.197704",
     "exception": false,
     "start_time": "2024-02-08T13:21:44.179061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model_predictions_to_csv(model, test_dataset, output_filename='submission.csv'):\n",
    "    \n",
    "    try:\n",
    "        # save the 'PassengerId' column\n",
    "        PassengerId = test_dataset['PassengerId']\n",
    "        # clean the dataset\n",
    "        test_dataset = data_cleaning(test_dataset)\n",
    "        print(test_dataset.info())\n",
    "        # make predictions using the provided model\n",
    "        y_pred = model.predict(test_dataset)\n",
    "\n",
    "        # create a DataFrame with 'PassengerId' and the predictions\n",
    "        submission_df = pd.DataFrame({\n",
    "            'PassengerId': PassengerId,\n",
    "            'Survived': y_pred\n",
    "        })\n",
    "\n",
    "        # save the DataFrame to a CSV file\n",
    "        submission_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Your submission was successfully saved to {output_filename}!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # handle any exceptions that might occur\n",
    "        print(\"An error occurred while saving the submission:\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0029ea15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:44.217599Z",
     "iopub.status.busy": "2024-02-08T13:21:44.217352Z",
     "iopub.status.idle": "2024-02-08T13:21:44.222974Z",
     "shell.execute_reply": "2024-02-08T13:21:44.222137Z"
    },
    "papermill": {
     "duration": 0.017659,
     "end_time": "2024-02-08T13:21:44.224752",
     "exception": false,
     "start_time": "2024-02-08T13:21:44.207093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=3):\n",
    "    '''Train a K-Nearest Neighbors classifier and evaluate its accuracy.'''\n",
    "    \n",
    "    # initialize the KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    # fit the model on the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the labels for the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "    # calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy: .2f}')\n",
    "    \n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccbc4361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:44.244882Z",
     "iopub.status.busy": "2024-02-08T13:21:44.244587Z",
     "iopub.status.idle": "2024-02-08T13:21:44.269624Z",
     "shell.execute_reply": "2024-02-08T13:21:44.268528Z"
    },
    "papermill": {
     "duration": 0.037226,
     "end_time": "2024-02-08T13:21:44.271572",
     "exception": false,
     "start_time": "2024-02-08T13:21:44.234346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.79\n"
     ]
    }
   ],
   "source": [
    "# test it when K is 3\n",
    "knn = train_and_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=3)\n",
    "# save_model_predictions_to_csv(knn, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ea7014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:44.291577Z",
     "iopub.status.busy": "2024-02-08T13:21:44.291319Z",
     "iopub.status.idle": "2024-02-08T13:21:44.301171Z",
     "shell.execute_reply": "2024-02-08T13:21:44.300221Z"
    },
    "papermill": {
     "duration": 0.022451,
     "end_time": "2024-02-08T13:21:44.303368",
     "exception": false,
     "start_time": "2024-02-08T13:21:44.280917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Survived    891 non-null    int64  \n",
      " 1   Pclass      891 non-null    int64  \n",
      " 2   Age         891 non-null    float64\n",
      " 3   SibSp       891 non-null    int64  \n",
      " 4   Parch       891 non-null    int64  \n",
      " 5   Fare        891 non-null    float64\n",
      " 6   Sex_female  891 non-null    int64  \n",
      " 7   Sex_male    891 non-null    int64  \n",
      " 8   Embarked_C  891 non-null    int64  \n",
      " 9   Embarked_Q  891 non-null    int64  \n",
      " 10  Embarked_S  891 non-null    int64  \n",
      "dtypes: float64(2), int64(9)\n",
      "memory usage: 76.7 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a53e37ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:44.325608Z",
     "iopub.status.busy": "2024-02-08T13:21:44.325370Z",
     "iopub.status.idle": "2024-02-08T13:21:45.945478Z",
     "shell.execute_reply": "2024-02-08T13:21:45.944577Z"
    },
    "papermill": {
     "duration": 1.63255,
     "end_time": "2024-02-08T13:21:45.947672",
     "exception": false,
     "start_time": "2024-02-08T13:21:44.315122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value for 'k' is 10\n"
     ]
    }
   ],
   "source": [
    "#### implement K-fold cross-validation to choose the optimal K\n",
    "knn = KNeighborsClassifier()\n",
    "# define the parameter grid\n",
    "param_grid = {'n_neighbors': range(1, 31)}\n",
    "# use GridSearchCV\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5) # cv is the number of folds\n",
    "# fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "# get the best parameter\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "print(f\"The best value for 'k' is {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fcba485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:45.968689Z",
     "iopub.status.busy": "2024-02-08T13:21:45.968394Z",
     "iopub.status.idle": "2024-02-08T13:21:45.995488Z",
     "shell.execute_reply": "2024-02-08T13:21:45.994598Z"
    },
    "papermill": {
     "duration": 0.039538,
     "end_time": "2024-02-08T13:21:45.997321",
     "exception": false,
     "start_time": "2024-02-08T13:21:45.957783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it when K is 4\n",
    "train_and_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace819dc",
   "metadata": {
    "papermill": {
     "duration": 0.009679,
     "end_time": "2024-02-08T13:21:46.016727",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.007048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> > ### Logistic regression: \n",
    "> > This is a statistical model that can model a binomial outcome with one or more explanatory variables. It is used extensively in many fields, including the medical and social sciences.  \n",
    "> \n",
    "> Pros:\n",
    "> 1. it can perform well when the dataset is linearly separable or when the boundary between classes can be approximated with a linear combination of features.\n",
    "> 2. logistic regression not only provides a classification but also gives the probabilities of the outcome, which can be a valuable insight.\n",
    "> 3. can be extended to multiclass classification problems.\n",
    "> 4. it is computationally less intensive.\n",
    "> \n",
    "> Cons:\n",
    "> 1. it assumes a linear relationship between the independent variables and log odds of the dependent variables.\n",
    "> 2. logistic regression can't capture complex relationships with non-linear boundaries as accurately as neural networks and decision trees.\n",
    "> 3. it is sensitive to outliers and may need scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0c68386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:46.037251Z",
     "iopub.status.busy": "2024-02-08T13:21:46.036979Z",
     "iopub.status.idle": "2024-02-08T13:21:46.043642Z",
     "shell.execute_reply": "2024-02-08T13:21:46.042859Z"
    },
    "papermill": {
     "duration": 0.019094,
     "end_time": "2024-02-08T13:21:46.045514",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.026420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_logreg(X_train, y_train, X_test, y_test):\n",
    "    '''Train a logistic regression classifier and evaluate its accuracy.'''\n",
    "    \n",
    "    # initialize the logistic model\n",
    "    logreg = LogisticRegression()\n",
    "    # fit the model to the training data\n",
    "    logreg.fit(X_train, y_train)\n",
    "    # predict probabilities\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    # calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # evaluate accuracy\n",
    "    print('#' * 50)\n",
    "    print(f\"Accuracy:\\n {accuracy: .2f}\")\n",
    "\n",
    "    # evaluate classification report\n",
    "    print('#' * 50)\n",
    "    print(f\"classification report:\\n {classification_report(y_test, y_pred)}\")\n",
    "    \n",
    "    # access the model's coefficients and intercept\n",
    "    coefficients = logreg.coef_\n",
    "    intercept = logreg.intercept_\n",
    "    # matching the coefficients to the feature names\n",
    "    feature_importance = pd.DataFrame(data=coefficients.T, index=X.columns, columns=['Coefficient'])\n",
    "    print('#' * 50)\n",
    "    print(f\"feature importance:\\n {feature_importance}\")\n",
    "    \n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c0a7a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:46.066055Z",
     "iopub.status.busy": "2024-02-08T13:21:46.065764Z",
     "iopub.status.idle": "2024-02-08T13:21:46.088394Z",
     "shell.execute_reply": "2024-02-08T13:21:46.087286Z"
    },
    "papermill": {
     "duration": 0.035278,
     "end_time": "2024-02-08T13:21:46.090547",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.055269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Accuracy:\n",
      "  0.81\n",
      "##################################################\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.85       157\n",
      "           1       0.80      0.73      0.76       111\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.80      0.80       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n",
      "##################################################\n",
      "feature importance:\n",
      "             Coefficient\n",
      "Pclass        -0.754826\n",
      "Age           -0.425000\n",
      "SibSp         -0.324014\n",
      "Parch         -0.080439\n",
      "Fare           0.133127\n",
      "Sex_female     0.613900\n",
      "Sex_male      -0.613900\n",
      "Embarked_C     0.116179\n",
      "Embarked_Q     0.031204\n",
      "Embarked_S    -0.120456\n"
     ]
    }
   ],
   "source": [
    "logreg = train_and_evaluate_logreg(X_train, y_train, X_test, y_test)\n",
    "# save_model_predictions_to_csv(logreg, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc017d40",
   "metadata": {
    "papermill": {
     "duration": 0.01014,
     "end_time": "2024-02-08T13:21:46.111083",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.100943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> > ### Random Forest: \n",
    "> > This is an ensemble machine learning algorithm that combines multiple decision trees to create a more accurate and robust model. It's particularly well-suited for classification and regression tasks and works well with both categorical and continuous data.\n",
    "> \n",
    "> Pros: \n",
    "> 1. it can be used for both classification and regression tasks and has the ability to handle large datasets with higher dimensionality.\n",
    "> 2. it can capture nonlinearity in the data by combining the results from various trees.\n",
    "> 3. due to the averaging of multiple trees, it is quite robust to noisein the input data.\n",
    "> \n",
    "> Cons:\n",
    "> 1. Random Forest models are not easily interpretable.\n",
    "> 2. it can be computationly intensive and slow to train.\n",
    "> 3. it's not ideal for linear problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f30f79e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:46.131725Z",
     "iopub.status.busy": "2024-02-08T13:21:46.131484Z",
     "iopub.status.idle": "2024-02-08T13:21:46.136546Z",
     "shell.execute_reply": "2024-02-08T13:21:46.135737Z"
    },
    "papermill": {
     "duration": 0.017544,
     "end_time": "2024-02-08T13:21:46.138391",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.120847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_rf(X_train, y_train, X_test, y_test):\n",
    "    '''Train a random forest classifier and evaluate its accuracy.'''\n",
    "    \n",
    "    # initialize the Random Forest model\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    # fit the model to the training data\n",
    "    rf.fit(X_train, y_train)\n",
    "    # predict class\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # evaluate accuracy\n",
    "    print(f\"Accuracy:\\n {accuracy_score(y_test, y_pred)}\")\n",
    "    # detailed classification report\n",
    "    print(f\"classification report:\\n {classification_report(y_test, y_pred)}\")\n",
    "    \n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a75f2b25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:46.159662Z",
     "iopub.status.busy": "2024-02-08T13:21:46.159426Z",
     "iopub.status.idle": "2024-02-08T13:21:46.427241Z",
     "shell.execute_reply": "2024-02-08T13:21:46.426107Z"
    },
    "papermill": {
     "duration": 0.281213,
     "end_time": "2024-02-08T13:21:46.429881",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.148668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " 0.7798507462686567\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       157\n",
      "           1       0.75      0.69      0.72       111\n",
      "\n",
      "    accuracy                           0.78       268\n",
      "   macro avg       0.78      0.77      0.77       268\n",
      "weighted avg       0.78      0.78      0.78       268\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      418 non-null    int64  \n",
      " 1   Age         418 non-null    float64\n",
      " 2   SibSp       418 non-null    int64  \n",
      " 3   Parch       418 non-null    int64  \n",
      " 4   Fare        418 non-null    float64\n",
      " 5   Sex_female  418 non-null    int64  \n",
      " 6   Sex_male    418 non-null    int64  \n",
      " 7   Embarked_C  418 non-null    int64  \n",
      " 8   Embarked_Q  418 non-null    int64  \n",
      " 9   Embarked_S  418 non-null    int64  \n",
      "dtypes: float64(2), int64(8)\n",
      "memory usage: 32.8 KB\n",
      "None\n",
      "Your submission was successfully saved to submission.csv!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf = train_and_evaluate_rf(X_train, y_train, X_test, y_test)\n",
    "save_model_predictions_to_csv(rf, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adfca36",
   "metadata": {
    "papermill": {
     "duration": 0.00995,
     "end_time": "2024-02-08T13:21:46.450201",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.440251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> > ### Deep Learning:\n",
    "> > \n",
    "> > Deep learning is a subset of machine learning that utilizes artificial neural networks with multiple layers—hence the term \"deep\"—to model and understand complex patterns in data. It is known for its effectiveness in tasks that deal with unstructured data like images, text, and audio.\n",
    "> \n",
    "> Pros:\n",
    "> 1. Flexibility in handling unstructured data:** Deep learning models excel at processing data with high dimensionality and complexity, such as images, sound waves, and text.\n",
    "> 2. High accuracy: They can achieve high levels of accuracy in various applications, including image recognition, natural language processing, and speech recognition, given enough data.\n",
    "> 3. Automatic feature extraction: These models can automatically learn the representations needed for feature detection or classification, eliminating the need for manual feature engineering.\n",
    "> \n",
    "> Cons:\n",
    "> 1. Large data requirement: Deep learning models typically require vast amounts of labeled data to train effectively.\n",
    "> 2. Computational intensity: The training process for deep learning models is resource-intensive, often necessitating the use of GPUs or even distributed computing environments.\n",
    "> 3. Opacity: Often considered as \"black boxes,\" deep learning models can be challenging to interpret, making it hard to understand the exact reasons behind their decisions or predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3a7eed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:46.471279Z",
     "iopub.status.busy": "2024-02-08T13:21:46.470988Z",
     "iopub.status.idle": "2024-02-08T13:21:46.542502Z",
     "shell.execute_reply": "2024-02-08T13:21:46.541458Z"
    },
    "papermill": {
     "duration": 0.084297,
     "end_time": "2024-02-08T13:21:46.544445",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.460148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 10])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "#### create a custom dataset class that inherits torch.utils.data.Dataset\n",
    "# create TabularDataset class in order to use DataLoader\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n",
    "\n",
    "# create PyTorch Dataset objects\n",
    "train_dataset = TabularDataset(X_train, y_train)\n",
    "test_dataset = TabularDataset(X_test, y_test)\n",
    "\n",
    "# create DataLoaders\n",
    "# in each epoch, the train process iterate each bach until all samples are calculated\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# create an iterator over the dataset\n",
    "train_iter = iter(train_loader)\n",
    "# get the next batch\n",
    "features, labels = next(train_iter)\n",
    "# print the shapes\n",
    "print(f'Feature batch shape: {features.size()}')\n",
    "print(f'Labels batch shape: {labels.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09ed0d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:46.566064Z",
     "iopub.status.busy": "2024-02-08T13:21:46.565737Z",
     "iopub.status.idle": "2024-02-08T13:21:46.572736Z",
     "shell.execute_reply": "2024-02-08T13:21:46.571984Z"
    },
    "papermill": {
     "duration": 0.019855,
     "end_time": "2024-02-08T13:21:46.574537",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.554682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### define the model\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, num_features, num_classes=1):  # default num_classes to 1 for binary classification\n",
    "        super().__init__()\n",
    "        self.sequential1 = nn.Sequential(\n",
    "            nn.Linear(num_features, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.sequential2 = nn.Sequential(\n",
    "            nn.Linear(64, 48),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.sequential3 = nn.Sequential(\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_layer = nn.Linear(32, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential1(x)\n",
    "        x = self.sequential2(x)\n",
    "        x = self.sequential3(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))  # using sigmoid for binary classification\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3f65009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:46.596379Z",
     "iopub.status.busy": "2024-02-08T13:21:46.596106Z",
     "iopub.status.idle": "2024-02-08T13:21:46.604501Z",
     "shell.execute_reply": "2024-02-08T13:21:46.603791Z"
    },
    "papermill": {
     "duration": 0.021512,
     "end_time": "2024-02-08T13:21:46.606334",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.584822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### define the model 2\n",
    "class ClassificationModel_2(nn.Module):\n",
    "    def __init__(self, num_features, num_classes=1, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(num_features, 64)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.layer2 = nn.Linear(64, 48)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(48)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.layer3 = nn.Linear(48, 32)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(32)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.output_layer = nn.Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch_norm1(self.layer1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.batch_norm2(self.layer2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.relu(self.batch_norm3(self.layer3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = torch.sigmoid(self.output_layer(x))  # still using sigmoid for binary classification\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24641b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T13:21:46.628261Z",
     "iopub.status.busy": "2024-02-08T13:21:46.627992Z",
     "iopub.status.idle": "2024-02-08T13:22:22.220654Z",
     "shell.execute_reply": "2024-02-08T13:22:22.219486Z"
    },
    "papermill": {
     "duration": 35.606107,
     "end_time": "2024-02-08T13:22:22.222735",
     "exception": false,
     "start_time": "2024-02-08T13:21:46.616628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 0.7928899943828582\n",
      "Epoch 101/1000, Loss: 0.6304153621196746\n",
      "Epoch 201/1000, Loss: 0.6226101160049439\n",
      "Epoch 301/1000, Loss: 0.6233940899372101\n",
      "Epoch 401/1000, Loss: 0.619364058971405\n",
      "Epoch 501/1000, Loss: 0.618149733543396\n",
      "Epoch 601/1000, Loss: 0.6157218813896179\n",
      "Epoch 701/1000, Loss: 0.6165882587432862\n",
      "Epoch 801/1000, Loss: 0.6165055513381958\n",
      "Epoch 901/1000, Loss: 0.6130147635936737\n",
      "Accuracy of the model on the test data: 80.97%\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the ClassificationModel with the number of features from training data\n",
    "model = ClassificationModel_2(num_features=X_train.shape[1])\n",
    "\n",
    "# use BCEWithLogitsLoss which combines a sigmoid layer and the BCELoss in one single class\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# initialize the optimizer with the Adam algorithm and a learning rate of 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# set the device to cuda if available, otherwise use cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# transfer the model to the chosen device\n",
    "model.to(device)\n",
    "\n",
    "# set the number of epochs for training\n",
    "num_epochs = 1000\n",
    "\n",
    "# start the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "    # initialize the total loss variable\n",
    "    total_loss = 0\n",
    "\n",
    "    # iterate over batches of data from the train_loader\n",
    "    for inputs, labels in train_loader:\n",
    "        # transfer inputs and labels to the device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # reset the gradients of the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute the model outputs\n",
    "        outputs = model(inputs)\n",
    "        # calculate the loss between outputs and labels\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        # backward pass: compute the gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # add the current loss to the total loss\n",
    "        total_loss += loss.item()\n",
    "        # update the model parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    # print the loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# switch off gradients for validation, saves memory and computations\n",
    "with torch.no_grad():\n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "    # initialize correct prediction count\n",
    "    correct = 0\n",
    "    # initialize total prediction count\n",
    "    total = 0\n",
    "\n",
    "    # iterate over batches of data from the test_loader\n",
    "    for inputs, labels in test_loader:\n",
    "        # transfer inputs and labels to the device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # forward pass: compute the model outputs\n",
    "        outputs = model(inputs)\n",
    "        # convert outputs probabilities to predicted class (0 or 1)\n",
    "        predicted = outputs.round()\n",
    "        # count the total number of labels\n",
    "        total += labels.size(0)\n",
    "        # count the number of correct predictions\n",
    "        correct += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "\n",
    "# calculate the accuracy of predictions\n",
    "accuracy = (correct / total) * 100\n",
    "# print the accuracy of the model on the test data\n",
    "print(f'Accuracy of the model on the test data: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 48.897952,
   "end_time": "2024-02-08T13:22:23.856058",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-08T13:21:34.958106",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
