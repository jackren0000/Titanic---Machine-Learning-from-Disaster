{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096e0363",
   "metadata": {
    "papermill": {
     "duration": 0.008056,
     "end_time": "2024-02-06T10:06:39.966442",
     "exception": false,
     "start_time": "2024-02-06T10:06:39.958386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Data Analysis of Titanic Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff391b1",
   "metadata": {
    "papermill": {
     "duration": 0.007321,
     "end_time": "2024-02-06T10:06:39.981286",
     "exception": false,
     "start_time": "2024-02-06T10:06:39.973965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define the objective:\n",
    "*The goal of this data analysis is to find relevance and patterns of the dataset, using statistical method and data visualization to show a clear relationship between different features within the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd37e1d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:39.997552Z",
     "iopub.status.busy": "2024-02-06T10:06:39.997175Z",
     "iopub.status.idle": "2024-02-06T10:06:45.649112Z",
     "shell.execute_reply": "2024-02-06T10:06:45.648155Z"
    },
    "papermill": {
     "duration": 5.662722,
     "end_time": "2024-02-06T10:06:45.651430",
     "exception": false,
     "start_time": "2024-02-06T10:06:39.988708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import KNN from scikit-learn library (especially for ML)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import data split method \n",
    "from sklearn.model_selection import train_test_split\n",
    "# import K-fold cross-validation method\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# import evaluation method\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# normalize the data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# import PyTorch for Deep Learning\n",
    "import torch\n",
    "# import neural network\n",
    "from torch import nn\n",
    "# import relative math functions\n",
    "import torch.nn.functional as F\n",
    "# import PyTorch DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac8dc2",
   "metadata": {
    "papermill": {
     "duration": 0.00754,
     "end_time": "2024-02-06T10:06:45.666782",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.659242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Collection:\n",
    "*Collect the relevant data from competition website, then convert it into pandas DataFrame.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02aea0da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:45.683265Z",
     "iopub.status.busy": "2024-02-06T10:06:45.682798Z",
     "iopub.status.idle": "2024-02-06T10:06:45.706776Z",
     "shell.execute_reply": "2024-02-06T10:06:45.705845Z"
    },
    "papermill": {
     "duration": 0.034632,
     "end_time": "2024-02-06T10:06:45.708855",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.674223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### load the data\n",
    "DIR_PATH = '/kaggle/input/titanic'\n",
    "train = pd.read_csv(os.path.join(DIR_PATH, 'train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b253d044",
   "metadata": {
    "papermill": {
     "duration": 0.007183,
     "end_time": "2024-02-06T10:06:45.723450",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.716267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Clearning:\n",
    "*Clean the unhelpful columns, NaN value, duplicates and inconsistencies.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a13ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:45.739415Z",
     "iopub.status.busy": "2024-02-06T10:06:45.738846Z",
     "iopub.status.idle": "2024-02-06T10:06:45.762957Z",
     "shell.execute_reply": "2024-02-06T10:06:45.761909Z"
    },
    "papermill": {
     "duration": 0.034313,
     "end_time": "2024-02-06T10:06:45.765012",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.730699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b95854f",
   "metadata": {
    "papermill": {
     "duration": 0.007223,
     "end_time": "2024-02-06T10:06:45.779975",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.772752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note: 'Age', 'Cabin' and 'Embarked' columns have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f969f603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:45.797844Z",
     "iopub.status.busy": "2024-02-06T10:06:45.797262Z",
     "iopub.status.idle": "2024-02-06T10:06:45.816869Z",
     "shell.execute_reply": "2024-02-06T10:06:45.816030Z"
    },
    "papermill": {
     "duration": 0.029956,
     "end_time": "2024-02-06T10:06:45.818731",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.788775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7388468e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:45.835645Z",
     "iopub.status.busy": "2024-02-06T10:06:45.834970Z",
     "iopub.status.idle": "2024-02-06T10:06:45.844773Z",
     "shell.execute_reply": "2024-02-06T10:06:45.843874Z"
    },
    "papermill": {
     "duration": 0.020224,
     "end_time": "2024-02-06T10:06:45.846635",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.826411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop unhelpful feature from the observation\n",
    "train.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "# drop NaN rows\n",
    "train.dropna(subset=['Age', 'Embarked'], inplace=True)\n",
    "# train.dropna(subset=['Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57795cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:45.863367Z",
     "iopub.status.busy": "2024-02-06T10:06:45.862670Z",
     "iopub.status.idle": "2024-02-06T10:06:45.875188Z",
     "shell.execute_reply": "2024-02-06T10:06:45.874363Z"
    },
    "papermill": {
     "duration": 0.022703,
     "end_time": "2024-02-06T10:06:45.876948",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.854245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0            1         0       3    male  22.0      1      0   7.2500        S\n",
       "1            2         1       1  female  38.0      1      0  71.2833        C\n",
       "2            3         1       3  female  26.0      0      0   7.9250        S\n",
       "3            4         1       1  female  35.0      1      0  53.1000        S\n",
       "4            5         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a1fc4",
   "metadata": {
    "papermill": {
     "duration": 0.008002,
     "end_time": "2024-02-06T10:06:45.892814",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.884812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cbec37",
   "metadata": {
    "papermill": {
     "duration": 0.007659,
     "end_time": "2024-02-06T10:06:45.908466",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.900807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Transformation:\n",
    "Normalize, scale, or encode data as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "879ddac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:45.925687Z",
     "iopub.status.busy": "2024-02-06T10:06:45.925136Z",
     "iopub.status.idle": "2024-02-06T10:06:46.058402Z",
     "shell.execute_reply": "2024-02-06T10:06:46.057541Z"
    },
    "papermill": {
     "duration": 0.14457,
     "end_time": "2024-02-06T10:06:46.060856",
     "exception": false,
     "start_time": "2024-02-06T10:06:45.916286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert categorical data into numerical data\n",
    "# use get_dummies() to perform one-hot encoding on 'Sex' and 'Embarked'\n",
    "train = pd.get_dummies(train, columns=['Sex', 'Embarked'])\n",
    "# separate the feature matrix and the target value\n",
    "X = train.drop('Survived', axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "# normalize the data\n",
    "# split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on training set only\n",
    "scaler.fit(X_train)\n",
    "# apply transform to both the training set and the test set\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821dd3d",
   "metadata": {
    "papermill": {
     "duration": 0.008945,
     "end_time": "2024-02-06T10:06:46.078798",
     "exception": false,
     "start_time": "2024-02-06T10:06:46.069853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Feature Engineering:\n",
    "Create new features from existing ones to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19645eb",
   "metadata": {
    "papermill": {
     "duration": 0.008325,
     "end_time": "2024-02-06T10:06:46.095824",
     "exception": false,
     "start_time": "2024-02-06T10:06:46.087499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd00cd",
   "metadata": {
    "papermill": {
     "duration": 0.008299,
     "end_time": "2024-02-06T10:06:46.112908",
     "exception": false,
     "start_time": "2024-02-06T10:06:46.104609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> > ### K-Nearest Neighbors: \n",
    "> > This is a type of instance-based supervised learning algorithm used for both classification and regression.  \n",
    "> \n",
    "> Pros:\n",
    "> 1. simple to understand and implement.\n",
    "> 2. no need to build a model, tune several parameters.\n",
    "> 3. the algorithm is versatile, it can be used for classification, regression and search (as in recommender system).\n",
    "> \n",
    "> Cons:\n",
    "> 1. the algorithm gets significantly slower as the dataset grows.\n",
    "> 2. requires high memory - needs to store all the training data.\n",
    "> 3. sensitive to the scale of the data and irrelevant features.\n",
    "> 4. typically not as accurate as more sophisticated methods, especially on datasets with a lot of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e038eca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:46.131862Z",
     "iopub.status.busy": "2024-02-06T10:06:46.131046Z",
     "iopub.status.idle": "2024-02-06T10:06:46.137265Z",
     "shell.execute_reply": "2024-02-06T10:06:46.136374Z"
    },
    "papermill": {
     "duration": 0.017833,
     "end_time": "2024-02-06T10:06:46.139255",
     "exception": false,
     "start_time": "2024-02-06T10:06:46.121422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=3):\n",
    "    '''Train a K-Nearest Neighbors classifier and evaluate its accuracy.'''\n",
    "    \n",
    "    # initialize the KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    # fit the model on the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the labels for the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "    # calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee1685e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:46.158007Z",
     "iopub.status.busy": "2024-02-06T10:06:46.157701Z",
     "iopub.status.idle": "2024-02-06T10:06:46.181440Z",
     "shell.execute_reply": "2024-02-06T10:06:46.180497Z"
    },
    "papermill": {
     "duration": 0.035357,
     "end_time": "2024-02-06T10:06:46.183415",
     "exception": false,
     "start_time": "2024-02-06T10:06:46.148058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.78\n"
     ]
    }
   ],
   "source": [
    "# test it when K is 3\n",
    "train_and_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9b2232e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:46.200877Z",
     "iopub.status.busy": "2024-02-06T10:06:46.200393Z",
     "iopub.status.idle": "2024-02-06T10:06:47.704688Z",
     "shell.execute_reply": "2024-02-06T10:06:47.703713Z"
    },
    "papermill": {
     "duration": 1.515438,
     "end_time": "2024-02-06T10:06:47.706938",
     "exception": false,
     "start_time": "2024-02-06T10:06:46.191500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value for 'k' is 4\n"
     ]
    }
   ],
   "source": [
    "#### implement K-fold cross-validation to choose the optimal K\n",
    "knn = KNeighborsClassifier()\n",
    "# define the parameter grid\n",
    "param_grid = {'n_neighbors': range(1, 31)}\n",
    "# use GridSearchCV\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5) # cv is the number of folds\n",
    "# fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "# get the best parameter\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "print(f\"The best value for 'k' is {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a38c461",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:47.724670Z",
     "iopub.status.busy": "2024-02-06T10:06:47.724365Z",
     "iopub.status.idle": "2024-02-06T10:06:47.744567Z",
     "shell.execute_reply": "2024-02-06T10:06:47.743542Z"
    },
    "papermill": {
     "duration": 0.031234,
     "end_time": "2024-02-06T10:06:47.746618",
     "exception": false,
     "start_time": "2024-02-06T10:06:47.715384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.78\n"
     ]
    }
   ],
   "source": [
    "# test it when K is 4\n",
    "train_and_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c25ca",
   "metadata": {
    "papermill": {
     "duration": 0.007945,
     "end_time": "2024-02-06T10:06:47.762868",
     "exception": false,
     "start_time": "2024-02-06T10:06:47.754923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> > ### Logistic regression: \n",
    "> > This is a statistical model that can model a binomial outcome with one or more explanatory variables. It is used extensively in many fields, including the medical and social sciences.  \n",
    "> \n",
    "> Pros:\n",
    "> 1. it can perform well when the dataset is linearly separable or when the boundary between classes can be approximated with a linear combination of features.\n",
    "> 2. logistic regression not only provides a classification but also gives the probabilities of the outcome, which can be a valuable insight.\n",
    "> 3. can be extended to multiclass classification problems.\n",
    "> 4. it is computationally less intensive.\n",
    "> \n",
    "> Cons:\n",
    "> 1. it assumes a linear relationship between the independent variables and log odds of the dependent variables.\n",
    "> 2. logistic regression can't capture complex relationships with non-linear boundaries as accurately as neural networks and decision trees.\n",
    "> 3. it is sensitive to outliers and may need scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c955d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:47.780303Z",
     "iopub.status.busy": "2024-02-06T10:06:47.780007Z",
     "iopub.status.idle": "2024-02-06T10:06:47.803699Z",
     "shell.execute_reply": "2024-02-06T10:06:47.802560Z"
    },
    "papermill": {
     "duration": 0.034713,
     "end_time": "2024-02-06T10:06:47.805582",
     "exception": false,
     "start_time": "2024-02-06T10:06:47.770869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       122\n",
      "           1       0.80      0.70      0.74        92\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.80      0.78      0.79       214\n",
      "weighted avg       0.79      0.79      0.79       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the logistic model\n",
    "logreg = LogisticRegression()\n",
    "# fit the model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "# predict probabilities\n",
    "y_pred = logreg.predict(X_test)\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# evaluate accuracy\n",
    "print(f\"Accuracy: {accuracy: .2f}\")\n",
    "\n",
    "# evaluate classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74128e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:47.823219Z",
     "iopub.status.busy": "2024-02-06T10:06:47.822966Z",
     "iopub.status.idle": "2024-02-06T10:06:47.829417Z",
     "shell.execute_reply": "2024-02-06T10:06:47.828579Z"
    },
    "papermill": {
     "duration": 0.017805,
     "end_time": "2024-02-06T10:06:47.831734",
     "exception": false,
     "start_time": "2024-02-06T10:06:47.813929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Coefficient\n",
      "PassengerId     0.081795\n",
      "Pclass         -1.231483\n",
      "Age            -0.571095\n",
      "SibSp          -0.269481\n",
      "Parch           0.010455\n",
      "Fare           -0.010707\n",
      "Sex_female      0.678744\n",
      "Sex_male       -0.678744\n",
      "Embarked_C      0.057743\n",
      "Embarked_Q     -0.011158\n",
      "Embarked_S     -0.049136\n"
     ]
    }
   ],
   "source": [
    "# access the model's coefficients and intercept\n",
    "coefficients = logreg.coef_\n",
    "intercept = logreg.intercept_\n",
    "# matching the coefficients to the feature names\n",
    "feature_importance = pd.DataFrame(data=coefficients.T, index=X.columns, columns=['Coefficient'])\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41788f6",
   "metadata": {
    "papermill": {
     "duration": 0.008139,
     "end_time": "2024-02-06T10:06:47.848415",
     "exception": false,
     "start_time": "2024-02-06T10:06:47.840276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> > ### Random Forest: \n",
    "> > This is an ensemble machine learning algorithm that combines multiple decision trees to create a more accurate and robust model. It's particularly well-suited for classification and regression tasks and works well with both categorical and continuous data.\n",
    "> \n",
    "> Pros: \n",
    "> 1. it can be used for both classification and regression tasks and has the ability to handle large datasets with higher dimensionality.\n",
    "> 2. it can capture nonlinearity in the data by combining the results from various trees.\n",
    "> 3. due to the averaging of multiple trees, it is quite robust to noisein the input data.\n",
    "> \n",
    "> Cons:\n",
    "> 1. Random Forest models are not easily interpretable.\n",
    "> 2. it can be computationly intensive and slow to train.\n",
    "> 3. it's not ideal for linear problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15d58e2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:47.866760Z",
     "iopub.status.busy": "2024-02-06T10:06:47.866102Z",
     "iopub.status.idle": "2024-02-06T10:06:48.104801Z",
     "shell.execute_reply": "2024-02-06T10:06:48.103750Z"
    },
    "papermill": {
     "duration": 0.250001,
     "end_time": "2024-02-06T10:06:48.106900",
     "exception": false,
     "start_time": "2024-02-06T10:06:47.856899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7570093457943925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       122\n",
      "           1       0.76      0.63      0.69        92\n",
      "\n",
      "    accuracy                           0.76       214\n",
      "   macro avg       0.76      0.74      0.75       214\n",
      "weighted avg       0.76      0.76      0.75       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# fit the model to the training data\n",
    "rf.fit(X_train, y_train)\n",
    "# predict class\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# evaluate accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "# detailed classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720238e1",
   "metadata": {
    "papermill": {
     "duration": 0.008264,
     "end_time": "2024-02-06T10:06:48.123769",
     "exception": false,
     "start_time": "2024-02-06T10:06:48.115505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> > ### Deep Learning:\n",
    "> > \n",
    "> > Deep learning is a subset of machine learning that utilizes artificial neural networks with multiple layers—hence the term \"deep\"—to model and understand complex patterns in data. It is known for its effectiveness in tasks that deal with unstructured data like images, text, and audio.\n",
    "> \n",
    "> Pros:\n",
    "> 1. Flexibility in handling unstructured data:** Deep learning models excel at processing data with high dimensionality and complexity, such as images, sound waves, and text.\n",
    "> 2. High accuracy: They can achieve high levels of accuracy in various applications, including image recognition, natural language processing, and speech recognition, given enough data.\n",
    "> 3. Automatic feature extraction: These models can automatically learn the representations needed for feature detection or classification, eliminating the need for manual feature engineering.\n",
    "> \n",
    "> Cons:\n",
    "> 1. Large data requirement: Deep learning models typically require vast amounts of labeled data to train effectively.\n",
    "> 2. Computational intensity: The training process for deep learning models is resource-intensive, often necessitating the use of GPUs or even distributed computing environments.\n",
    "> 3. Opacity: Often considered as \"black boxes,\" deep learning models can be challenging to interpret, making it hard to understand the exact reasons behind their decisions or predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a9525b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:48.141881Z",
     "iopub.status.busy": "2024-02-06T10:06:48.141569Z",
     "iopub.status.idle": "2024-02-06T10:06:48.209878Z",
     "shell.execute_reply": "2024-02-06T10:06:48.208801Z"
    },
    "papermill": {
     "duration": 0.079592,
     "end_time": "2024-02-06T10:06:48.211759",
     "exception": false,
     "start_time": "2024-02-06T10:06:48.132167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 11])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "#### create a custom dataset class that inherits torch.utils.data.Dataset\n",
    "# create TabularDataset class in order to use DataLoader\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n",
    "\n",
    "# create PyTorch Dataset objects\n",
    "train_dataset = TabularDataset(X_train, y_train)\n",
    "test_dataset = TabularDataset(X_test, y_test)\n",
    "\n",
    "# create DataLoaders\n",
    "# in each epoch, the train process iterate each bach until all samples are calculated\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# create an iterator over the dataset\n",
    "train_iter = iter(train_loader)\n",
    "# get the next batch\n",
    "features, labels = next(train_iter)\n",
    "# print the shapes\n",
    "print(f'Feature batch shape: {features.size()}')\n",
    "print(f'Labels batch shape: {labels.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71c326ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:48.230907Z",
     "iopub.status.busy": "2024-02-06T10:06:48.230609Z",
     "iopub.status.idle": "2024-02-06T10:06:48.237774Z",
     "shell.execute_reply": "2024-02-06T10:06:48.236923Z"
    },
    "papermill": {
     "duration": 0.018739,
     "end_time": "2024-02-06T10:06:48.239580",
     "exception": false,
     "start_time": "2024-02-06T10:06:48.220841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### define the model\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, num_features, num_classes=1):  # default num_classes to 1 for binary classification\n",
    "        super().__init__()\n",
    "        self.sequential1 = nn.Sequential(\n",
    "            nn.Linear(num_features, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.sequential2 = nn.Sequential(\n",
    "            nn.Linear(64, 48),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.sequential3 = nn.Sequential(\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_layer = nn.Linear(32, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential1(x)\n",
    "        x = self.sequential2(x)\n",
    "        x = self.sequential3(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))  # using sigmoid for binary classification\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dadb7181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:06:48.257913Z",
     "iopub.status.busy": "2024-02-06T10:06:48.257387Z",
     "iopub.status.idle": "2024-02-06T10:06:58.653644Z",
     "shell.execute_reply": "2024-02-06T10:06:58.652569Z"
    },
    "papermill": {
     "duration": 10.407587,
     "end_time": "2024-02-06T10:06:58.655720",
     "exception": false,
     "start_time": "2024-02-06T10:06:48.248133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Loss: 0.7738960236310959\n",
      "Epoch 101/400, Loss: 0.6028265058994293\n",
      "Epoch 201/400, Loss: 0.6019479408860207\n",
      "Epoch 301/400, Loss: 0.6028707176446915\n",
      "Accuracy of the model on the test data: 76.64%\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the ClassificationModel with the number of features from training data\n",
    "model = ClassificationModel(num_features=X_train.shape[1])\n",
    "\n",
    "# use BCEWithLogitsLoss which combines a sigmoid layer and the BCELoss in one single class\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# initialize the optimizer with the Adam algorithm and a learning rate of 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# set the device to cuda if available, otherwise use cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# transfer the model to the chosen device\n",
    "model.to(device)\n",
    "\n",
    "# set the number of epochs for training\n",
    "num_epochs = 400\n",
    "\n",
    "# start the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "    # initialize the total loss variable\n",
    "    total_loss = 0\n",
    "\n",
    "    # iterate over batches of data from the train_loader\n",
    "    for inputs, labels in train_loader:\n",
    "        # transfer inputs and labels to the device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # reset the gradients of the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute the model outputs\n",
    "        outputs = model(inputs)\n",
    "        # calculate the loss between outputs and labels\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        # backward pass: compute the gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # add the current loss to the total loss\n",
    "        total_loss += loss.item()\n",
    "        # update the model parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    # print the loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# switch off gradients for validation, saves memory and computations\n",
    "with torch.no_grad():\n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "    # initialize correct prediction count\n",
    "    correct = 0\n",
    "    # initialize total prediction count\n",
    "    total = 0\n",
    "\n",
    "    # iterate over batches of data from the test_loader\n",
    "    for inputs, labels in test_loader:\n",
    "        # transfer inputs and labels to the device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # forward pass: compute the model outputs\n",
    "        outputs = model(inputs)\n",
    "        # convert outputs probabilities to predicted class (0 or 1)\n",
    "        predicted = outputs.round()\n",
    "        # count the total number of labels\n",
    "        total += labels.size(0)\n",
    "        # count the number of correct predictions\n",
    "        correct += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "\n",
    "# calculate the accuracy of predictions\n",
    "accuracy = (correct / total) * 100\n",
    "# print the accuracy of the model on the test data\n",
    "print(f'Accuracy of the model on the test data: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.159222,
   "end_time": "2024-02-06T10:07:01.377781",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-06T10:06:37.218559",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
